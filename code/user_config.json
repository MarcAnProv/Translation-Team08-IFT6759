{
  "random_seed": 42,
  "model_file": "../model/my_model",
  "target_model": "bert_model",
  "nb_epoch": 10,
  "code_profiling_enabled": false,
  "ignore_checkpoints": true,
  "model_info": "../model/training_info.npy",
  "train_data_folder": "/project/cq-training-1/project2/teams/team08/data/",
  "val_data_folder": "../data",
  "transformer_dropout_rate": 0.1,
  "transformer_batch_size": 128,
  "transformer_epochs": 30,
  "transformer_num_layers": 4,
  "transformer_model_dimensions": 128,
  "transformer_num_heads": 8,
  "transformer_dff": 512,
  "transformer_checkpoint_path": "../model/en_fr_474k",
  "inp_language": "en",
  "target_language": "fr",
  "train_data_path_en": "../data/processed_474k_en.txt",
  "train_data_path_fr": "../data/unaligned.fr",
  "val_data_path_en": "../data/test_en.txt",
  "val_data_path_fr": "../data/test_fr.txt",
  "test_data_path_en": "../log/test_en_bleu.txt",
  "test_data_path_fr": "../log/test_fr_bleu.txt",
  "tokenizer_path_en": "../tokenizer_data_en_30k",
  "tokenizer_path_fr": "../tokenizer_data_fr_30k",
  "use_pretrained_emb": true,
  "pretrained_emb_path_en": "../pretrained_embeddings/tf_bert_for_masked_lm_epoch_16_loss_9.00_30k_en.npy",
  "pretrained_emb_path_fr": "../pretrained_embeddings/tf_bert_for_masked_lm_epoch_27_loss_8.78_30k_fr.npy",
  "max_length_en": 80,
  "max_length_fr": 120,
  "compute_bleu": true
}