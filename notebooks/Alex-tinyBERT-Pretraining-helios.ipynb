{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring pip: markers 'python_version < \"3\"' don't match your environment\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: tensorflow-gpu in /localscratch/guest139.356788.0/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (0.1.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (0.2.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from tensorflow-gpu) (1.13.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (1.25.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/site-packages/wheel-0.33.4-py3.7.egg (from tensorflow-gpu) (0.33.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (2.3.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (0.8.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (3.11.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (1.18.2)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (1.0.8)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (2.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorflow-gpu) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/python/3.7.4/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow-gpu) (40.8.0)\n",
      "Requirement already satisfied: h5py in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.11.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.23.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring pip: markers 'python_version < \"3\"' don't match your environment\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /home/guest139/s3transfer/botocore\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from botocore==1.15.37) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from botocore==1.15.37) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from botocore==1.15.37) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from botocore==1.15.37) (1.25.8)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.15.37) (1.13.0)\n",
      "Building wheels for collected packages: botocore\n",
      "  Building wheel for botocore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-2ep3ytav/wheels/fe/ab/37/f8ebb3c769c11a806041a139b0ab3964015975a5bb08071dc6\n",
      "Successfully built botocore\n",
      "Installing collected packages: botocore\n",
      "  Found existing installation: botocore 1.15.37\n",
      "    Uninstalling botocore-1.15.37:\n",
      "      Successfully uninstalled botocore-1.15.37\n",
      "Successfully installed botocore-1.15.37\n",
      "Ignoring pip: markers 'python_version < \"3\"' don't match your environment\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /home/guest139/s3transfer\n",
      "Requirement already satisfied: botocore<2.0a.0,>=1.12.36 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from s3transfer==0.3.3) (1.15.37)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from botocore<2.0a.0,>=1.12.36->s3transfer==0.3.3) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from botocore<2.0a.0,>=1.12.36->s3transfer==0.3.3) (0.15.2)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from botocore<2.0a.0,>=1.12.36->s3transfer==0.3.3) (1.25.8)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from botocore<2.0a.0,>=1.12.36->s3transfer==0.3.3) (0.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0a.0,>=1.12.36->s3transfer==0.3.3) (1.13.0)\n",
      "Building wheels for collected packages: s3transfer\n",
      "  Building wheel for s3transfer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-swmvy5dy/wheels/21/b5/7f/8dc1ac8a07cf30a6f8e4c8c6af478ed702be97967619f38b8b\n",
      "Successfully built s3transfer\n",
      "Installing collected packages: s3transfer\n",
      "  Found existing installation: s3transfer 0.3.3\n",
      "    Uninstalling s3transfer-0.3.3:\n",
      "      Successfully uninstalled s3transfer-0.3.3\n",
      "Successfully installed s3transfer-0.3.3\n",
      "Ignoring pip: markers 'python_version < \"3\"' don't match your environment\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /home/guest139/sacremoses\n",
      "Requirement already satisfied: regex in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from sacremoses==0.0.38) (2019.11.1)\n",
      "Requirement already satisfied: six in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from sacremoses==0.0.38) (1.13.0)\n",
      "Requirement already satisfied: click in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from sacremoses==0.0.38) (7.1.1)\n",
      "Requirement already satisfied: joblib in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from sacremoses==0.0.38) (0.14.1)\n",
      "Requirement already satisfied: tqdm in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from sacremoses==0.0.38) (4.40.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-qjd59t2y/wheels/e0/47/84/d17295db70c2c5f374b2f64c5b161ca6324e0dff3d92eaf80c\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses\n",
      "  Found existing installation: sacremoses 0.0.38\n",
      "    Uninstalling sacremoses-0.0.38:\n",
      "      Successfully uninstalled sacremoses-0.0.38\n",
      "Successfully installed sacremoses-0.0.38\n",
      "Ignoring pip: markers 'python_version < \"3\"' don't match your environment\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/avx, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Processing /home/guest139/transformers\n",
      "Requirement already satisfied: numpy in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (1.18.2)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (0.5.2)\n",
      "Requirement already satisfied: boto3 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (1.12.31)\n",
      "Requirement already satisfied: filelock in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (3.0.12)\n",
      "Requirement already satisfied: requests in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (4.40.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (2019.11.1)\n",
      "Requirement already satisfied: sentencepiece in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (0.1.82)\n",
      "Requirement already satisfied: sacremoses in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from transformers==2.8.0) (0.0.38)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from boto3->transformers==2.8.0) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from boto3->transformers==2.8.0) (1.15.37)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from boto3->transformers==2.8.0) (0.9.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests->transformers==2.8.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests->transformers==2.8.0) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests->transformers==2.8.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from requests->transformers==2.8.0) (1.25.8)\n",
      "Requirement already satisfied: joblib in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from sacremoses->transformers==2.8.0) (0.14.1)\n",
      "Requirement already satisfied: click in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from sacremoses->transformers==2.8.0) (7.1.1)\n",
      "Requirement already satisfied: six in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from sacremoses->transformers==2.8.0) (1.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/ipykernel/5.1.3/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers==2.8.0) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /localscratch/guest139.356788.0/lib/python3.7/site-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers==2.8.0) (0.15.2)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-mzmcpmqc/wheels/63/32/25/2e434bbe27e8807fd0665b43ecac20f96b0d8d8124eb8fc97f\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Found existing installation: transformers 2.8.0\n",
      "    Uninstalling transformers-2.8.0:\n",
      "      Successfully uninstalled transformers-2.8.0\n",
      "Successfully installed transformers-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-index /home/guest139/s3transfer/botocore\n",
    "!pip install --no-index /home/guest139/s3transfer\n",
    "!pip install --no-index /home/guest139/sacremoses\n",
    "!pip install --no-index /home/guest139/transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "en_file1 = '../data/train.lang1.no-punctuation/train.lang1'\n",
    "en_file2 = '../data/train.en.no-punctuation/unaligned.en'\n",
    "fr_file1 = '../data/train.lang2.no-punctuation/train.lang2'\n",
    "fr_file2 = '../data/train.fr.no-punctuation/unaligned.fr'\n",
    "# TODO: exclude the test set\n",
    "\n",
    "# lang_files = [en_file1, en_file2, fr_file1, fr_file2] TODO\n",
    "lang_files = [en_file2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize all files (whole strings (TODO: substrings, capitalization))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Add control tokens\n",
    "my_counter = Counter()\n",
    "for i in range(2):\n",
    "    my_counter.update([\"<START>\", \"<STOP>\", \"<UNK>\", \"<MASK>\", \"<SEP>\", \"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_tokens(raw_string):\n",
    "    return raw_string.split()\n",
    "\n",
    "line_lengths = []\n",
    "for lang_file in lang_files:\n",
    "    with open(lang_file) as f:\n",
    "        for line in f:\n",
    "            tokens = string_to_tokens(line)\n",
    "            line_lengths += [len(tokens)]\n",
    "            for token in tokens:\n",
    "                my_counter.update([token])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep tokens that occur more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tokens = np.array(list(my_counter.keys()))\n",
    "frequencies = np.array(list(my_counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_tokens = tokens[frequencies > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60014\n",
      "40145\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(retained_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create lookup table dict: string -> token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(range(len(retained_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 40142, 40143, 40144])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tokenizer_lut = dict(zip(retained_tokens,indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for tokenizing, padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     2,   292,  3228,  6307,  2514,   995,     7, 12783,\n",
       "            2,     1,     5,     5,     5,     5,     5,     5,     5,\n",
       "            5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
       "            5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
       "            5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
       "            5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
       "            5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
       "            5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_tokens(token_list, max_length):\n",
    "    if len(token_list) >= max_length:\n",
    "        token_list = token_list[:max_length]\n",
    "        token_list[(max_length-1)] = my_tokenizer_lut[\"<STOP>\"]\n",
    "    else:\n",
    "        while len(token_list) < max_length:\n",
    "            token_list = token_list + [my_tokenizer_lut[\"<PAD>\"]]\n",
    "    return token_list\n",
    "\n",
    "SENTENCE_LENGTH = 64\n",
    "def tokenize_string(raw_string, max_length=SENTENCE_LENGTH): # TODO: Better definition of sentence length\n",
    "    token_list = [my_tokenizer_lut[\"<START>\"]]\n",
    "    \n",
    "    for token in string_to_tokens(raw_string):\n",
    "        if token in my_tokenizer_lut:\n",
    "            token_list += [my_tokenizer_lut[token]]\n",
    "        else:\n",
    "            token_list += [my_tokenizer_lut[\"<UNK>\"]]\n",
    "    \n",
    "    token_list += [my_tokenizer_lut[\"<STOP>\"]]\n",
    "    \n",
    "    token_list = pad_tokens(token_list, max_length)\n",
    "    \n",
    "    return np.array(token_list)[None,:]\n",
    "        \n",
    "tokenize_string(\"The quick brown fox jumped over the lazy dog.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the second phase of the trials we just had different sizes small medium large and extra - large it 's true\n",
      "\n",
      "geng had been my host the previous january when i was the first us defense secretary to visit china acting as an interlocutor for president jimmy carter ’s administration\n",
      "\n",
      "so too does the idea that accommodating religious differences is dangerous\n",
      "\n",
      "mr president ladies and gentlemen the financial perspective outlines the scope of the eu ’s activities over coming years as well as providing a framework for such activities and determining how effective they will be\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(474000, 64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_file(filename):\n",
    "    with open(filename) as f:\n",
    "        tokens = []\n",
    "        for idx, line in enumerate(f):\n",
    "            if idx < 2:\n",
    "                print(line)\n",
    "            tokens += [tokenize_string(line)]\n",
    "    return np.concatenate(tokens,axis=0)\n",
    "\n",
    "x_true = tokenize_file(en_file2)\n",
    "x_true_val = tokenize_file(en_file1)\n",
    "x_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define masking strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  6,  7,  8,  9, 10,  7, 11, 12, 13, 14, 15,  3,  3, 18, 19,  3,\n",
       "       21,  3,  3, 23, 24, 25,  1,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask_tokens(true_tokens):\n",
    "    non_pad_tokens = true_tokens != my_tokenizer_lut[\"<PAD>\"]\n",
    "    random_masking_seed = np.random.uniform(0,1,(SENTENCE_LENGTH,)) * non_pad_tokens\n",
    "    \n",
    "    masking_targets = 0.85 < random_masking_seed # 15%\n",
    "    mask_token_targets = np.logical_and(0.85 < random_masking_seed, random_masking_seed < 0.85 + 0.15*0.8) # 80% of 15%\n",
    "    random_token_targets = np.logical_and(1.0 - 0.1*0.15 < random_masking_seed, random_masking_seed < 1.0) # 10% of 15%\n",
    "    \n",
    "    masked_tokens = true_tokens.copy()\n",
    "    masked_tokens[mask_token_targets] = my_tokenizer_lut[\"<MASK>\"]\n",
    "    masked_tokens[random_token_targets] = np.random.randint(0,len(my_tokenizer_lut),(random_token_targets.sum(),))\n",
    "#     masked_tokens[~mask_token_targets] = my_tokenizer_lut[\"<PAD>\"]\n",
    "\n",
    "    masked_true_tokens = true_tokens.copy()\n",
    "    masked_true_tokens[~masking_targets] = my_tokenizer_lut[\"<PAD>\"]\n",
    "    \n",
    "    attention_mask = true_tokens != my_tokenizer_lut[\"<PAD>\"]\n",
    "    \n",
    "    return masked_tokens, masking_targets, masked_true_tokens, attention_mask\n",
    "\n",
    "x_train, targets_train, masked_x_true, attention_mask = mask_tokens(x_true)\n",
    "x_train_val, targets_train_val, masked_x_true_val, attention_mask_val = mask_tokens(x_true_val)\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True, False, False,  True, False,\n",
       "         True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True,  True, False, False,  True, False,\n",
       "         True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  6,  7,  8,  9, 10,  7, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
       "        20, 21, 22, 19, 23, 24, 25,  1,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5],\n",
       "       [ 0,  2, 14, 26, 27, 28,  7, 29, 30, 31, 32, 33,  7, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41, 42, 43, 44,  6, 45, 46, 47, 48, 49,  1,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_true[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Override model to include masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0408 20:56:46.205807 47434534466560 file_utils.py:57] TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForMaskedLM, BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overriding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bert_with_mask(tf.keras.Model):\n",
    "    def __init__(self, config, onehot_mask):\n",
    "        super(bert_with_mask, self).__init__()\n",
    "        self.bert = TFBertForMaskedLM(config)\n",
    "        self.onehot_mask = onehot_mask\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mask = inputs[-1] # unpack mask from inputs\n",
    "        inputs = inputs[:-1]\n",
    "        outputs = self.bert(inputs)[0]\n",
    "        \n",
    "        outputs = tf.where(mask[:,:,None], outputs, self.onehot_mask[None,None,:])\n",
    "        \n",
    "        return (outputs,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define masking function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_mask = np.zeros(len(my_tokenizer_lut), dtype=np.float32)\n",
    "onehot_mask[my_tokenizer_lut[\"<PAD>\"]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0408 20:56:47.542387 47434534466560 configuration_utils.py:281] loading configuration file ../code/bert_config_tiny.json\n",
      "I0408 20:56:47.545097 47434534466560 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 128,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 512,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained('../code/bert_config_tiny.json')\n",
    "config.vocab_size = len(my_tokenizer_lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = bert_with_mask(config, onehot_mask)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model2.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "def data_generator_fn():\n",
    "    for x in x_true:\n",
    "        x_train, targets_train, masked_x_true, attention_mask = mask_tokens(x)\n",
    "        yield (x_train, attention_mask, targets_train), masked_x_true\n",
    "\n",
    "# dataset object\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator_fn,\n",
    "    output_types=((tf.int32, tf.bool, tf.bool), tf.int32),\n",
    "    output_shapes=(( tf.TensorShape((SENTENCE_LENGTH,)), tf.TensorShape((SENTENCE_LENGTH,)), tf.TensorShape((SENTENCE_LENGTH,)) ), tf.TensorShape((SENTENCE_LENGTH,)) )\n",
    ")\n",
    "dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "def data_generator_fn_val():\n",
    "    for x in x_true_val:\n",
    "        x_train, targets_train, masked_x_true, attention_mask = mask_tokens(x)\n",
    "        yield (x_train, attention_mask, targets_train), masked_x_true\n",
    "\n",
    "# dataset object\n",
    "dataset_val = tf.data.Dataset.from_generator(\n",
    "    data_generator_fn_val,\n",
    "    output_types=((tf.int32, tf.bool, tf.bool), tf.int32),\n",
    "    output_shapes=(( tf.TensorShape((SENTENCE_LENGTH,)), tf.TensorShape((SENTENCE_LENGTH,)), tf.TensorShape((SENTENCE_LENGTH,)) ), tf.TensorShape((SENTENCE_LENGTH,)) )\n",
    ")\n",
    "dataset_val = dataset_val.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/guest139.356788.0/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "W0408 20:56:56.682170 47434534466560 optimizer_v2.py:1043] Gradients do not exist for variables ['bert_with_mask/tf_bert_for_masked_lm/bert/pooler/dense/kernel:0', 'bert_with_mask/tf_bert_for_masked_lm/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "/localscratch/guest139.356788.0/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "W0408 20:56:59.367838 47434534466560 optimizer_v2.py:1043] Gradients do not exist for variables ['bert_with_mask/tf_bert_for_masked_lm/bert/pooler/dense/kernel:0', 'bert_with_mask/tf_bert_for_masked_lm/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14813/14813 [==============================] - 2414s 163ms/step - loss: 9.3840 - val_loss: 9.3408\n",
      "Epoch 2/10\n",
      " 7872/14813 [==============>...............] - ETA: 18:36 - loss: 9.3415"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288/14813 [=======================>......] - ETA: 6:44 - loss: 9.3392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14813/14813 [==============================] - 2402s 162ms/step - loss: 9.3379 - val_loss: 9.3191\n",
      "Epoch 3/10\n",
      " 1999/14813 [===>..........................] - ETA: 33:53 - loss: 9.3304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6523/14813 [============>.................] - ETA: 21:53 - loss: 9.3283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14813/14813 [==============================] - 2376s 160ms/step - loss: 9.3262 - val_loss: 9.3110\n",
      "Epoch 4/10\n",
      "10399/14813 [====================>.........] - ETA: 11:37 - loss: 9.3198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12164/14813 [=======================>......] - ETA: 6:59 - loss: 9.3193"
     ]
    }
   ],
   "source": [
    "hist = model2.fit(dataset, validation_data=dataset_val, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = tokenize_string(\"I drove to <MASK> .\")\n",
    "my_output = model2((my_input, tf.ones(my_input.shape[:2], dtype=tf.bool) ))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.top_k(my_output[0,4,:], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_tokenizer_lut = {v: k for k, v in my_tokenizer_lut.items()}\n",
    "for t in range(7):\n",
    "    print()\n",
    "    print(f\"t{t}:\")\n",
    "    for i in tf.nn.top_k(my_output[0,t,:], 5).indices.numpy():\n",
    "        print(inv_tokenizer_lut[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save/Load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tinyBERT3\n",
    "!mkdir tinyBERT3\n",
    "model2.save_weights('tinyBERT3/tinyBERT', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model\n",
    "new_model = bert_with_mask(config, onehot_mask)\n",
    "new_model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# This initializes the variables used by the optimizers,\n",
    "# as well as any stateful metric variables\n",
    "new_model.train_on_batch(dataset.take(1))\n",
    "\n",
    "# Load the state of the old model\n",
    "new_model.load_weights('tinyBERT3/tinyBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = tokenize_string(\"i drove to work\")\n",
    "my_output = new_model((my_input, tf.ones(my_input.shape[:2], dtype=tf.bool) ))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    print(inv_tokenizer_lut[my_input[0,i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(7):\n",
    "    print()\n",
    "    print(f\"t{t}:\")\n",
    "    for i, pct in zip(tf.nn.top_k(my_output[0,t,:], 2).indices.numpy(), tf.nn.top_k(my_output[0,t,:], 2).values.numpy()):\n",
    "        print(f\"Guess: {inv_tokenizer_lut[i]}, pct: {pct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
