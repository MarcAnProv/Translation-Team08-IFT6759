{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-index --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-index tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-index matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvVhUeaRO_nA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "#import tensorflow_datasets as tfds\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import unicodedata\n",
    "import re\n",
    "import gc\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ys0Y7XsBO_nY"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYVG_U1HO_ne"
   },
   "source": [
    "## Preprocessing: Tokenize, clean-up, load, padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4OBlaeO_nf"
   },
   "source": [
    "### Tokenize and clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEI1uWtjO_nh"
   },
   "outputs": [],
   "source": [
    "# Lower case for the translation\n",
    "# Load original english text as is\n",
    "# install requirement.txt\n",
    "# python -m spacy download fr_core_news_sm\n",
    "# correction of tokenizer.py: add encoding='utf-8' to open method\n",
    "# same thing for punctuation_remover.py\n",
    "# python tokenizer.py --input train.lang2 --output tokenized --lang fr --keep-empty-lines\n",
    "# python punctuation_remover.py --input train.lang2.tok --output tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpNtsXsjO_nn"
   },
   "source": [
    "### Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5nxMfzAO_no"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "DIRECTORY_URL = \"data/train/\"\n",
    "FILE_NAMES = [\"train.lang1\",\"train.lang2\"]\n",
    "\n",
    "#en_data = tf.data.TextLineDataset(os.path.join(DIRECTORY_URL, FILE_NAMES[0]))\n",
    "#fr_data = tf.data.TextLineDataset(os.path.join(DIRECTORY_URL, FILE_NAMES[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_text = []\n",
    "decoder_target_text = []\n",
    "\n",
    "with open(os.path.join(DIRECTORY_URL, FILE_NAMES[1]), 'r', encoding=\"UTF-8\") as fr_file:\n",
    "    for line in fr_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "\n",
    "        target_line = line[0]+\" <eos>\"\n",
    "        input_line = \"<bos> \"+line[0]\n",
    "\n",
    "        decoder_input_text.append(input_line)\n",
    "        decoder_target_text.append(target_line)\n",
    "    fr_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<bos> L’ idée de concilier les différences religieuses semble donc dangereuse .',\n",
       " '<bos> Monsieur le Président , Mesdames et Messieurs , les perspectives financières esquissent la portée des activités de l’ UE pour les années à venir , fournissent un cadre pour ces activités et déterminent leur efficacité .',\n",
       " '<bos> La réticence doit laisser place à une politique stimulante .']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_text[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L’ idée de concilier les différences religieuses semble donc dangereuse . <eos>',\n",
       " 'Monsieur le Président , Mesdames et Messieurs , les perspectives financières esquissent la portée des activités de l’ UE pour les années à venir , fournissent un cadre pour ces activités et déterminent leur efficacité . <eos>',\n",
       " 'La réticence doit laisser place à une politique stimulante . <eos>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_text[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_text = []\n",
    "with open(os.path.join(DIRECTORY_URL, FILE_NAMES[0]), 'r', encoding=\"UTF-8\") as en_file:\n",
    "    for line in en_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        encoder_input_text.append(line[0]+\" .\")\n",
    "    en_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so too does the idea that accommodating religious differences is dangerous .',\n",
       " 'mr president ladies and gentlemen the financial perspective outlines the scope of the eu ’s activities over coming years as well as providing a framework for such activities and determining how effective they will be .',\n",
       " 'reserve should turn into thought - provoking policy .']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_text[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 11000, 11000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_input_text), len(decoder_input_text), len(decoder_target_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8I2mb7eJO_oj"
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 13538\n",
      "Length of longest sentence in input: 91\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "input_tokenizer.fit_on_texts(encoder_input_text)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(encoder_input_text)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "num_words_input = len(word2idx_inputs) + 1\n",
    "print('Total unique words in the input: %s' % num_words_input)\n",
    "\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 155, 118, 1, 338, 8, 7411, 966, 1366, 7, 823]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_integer_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 35, 7, 14, 24]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sen_len = [len(tok) for tok in input_integer_seq]\n",
    "en_sen_len[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_sentences(text, max_len):\n",
    "    short_sentences = []\n",
    "    i=0\n",
    "    for t in text:\n",
    "        print(t)\n",
    "        print(t[:max_len])\n",
    "        short_sentences.append(t[:max_len])\n",
    "        i+=1\n",
    "        if i==10: break\n",
    "            \n",
    "    return short_sentences      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 155, 118, 1, 338, 8, 7411, 966, 1366, 7, 823]\n",
      "[42, 155, 118, 1, 338, 8, 7411, 966, 1366, 7]\n",
      "[40, 48, 272, 4, 280, 1, 172, 967, 4377, 1, 1245, 2, 1, 84, 75, 617, 131, 561, 102, 21, 122, 21, 2001, 6, 257, 13, 94, 617, 4, 3231, 108, 562, 31, 22, 15]\n",
      "[40, 48, 272, 4, 280, 1, 172, 967, 4377, 1]\n",
      "[2352, 46, 640, 88, 582, 7412, 95]\n",
      "[2352, 46, 640, 88, 582, 7412, 95]\n",
      "[10, 7, 52, 2353, 2588, 8, 11, 30, 79, 2166, 190, 186, 4, 2354]\n",
      "[10, 7, 52, 2353, 2588, 8, 11, 30, 79, 2166]\n",
      "[1, 29, 64, 25, 3740, 2355, 406, 85, 60, 1000, 1528, 20, 318, 1719, 2356, 4, 3232, 2, 60, 1367, 16, 5447, 24, 691]\n",
      "[1, 29, 64, 25, 3740, 2355, 406, 85, 60, 1000]\n",
      "[7413, 61, 23, 1302, 68]\n",
      "[7413, 61, 23, 1302, 68]\n",
      "[27, 28, 1, 583, 1, 887, 180, 59, 99, 12, 57, 202, 7, 39, 11, 18, 14, 1, 1132, 1, 1303, 80, 4, 96, 80, 5, 446, 1846, 4, 7414, 26, 46, 2357, 5, 888]\n",
      "[27, 28, 1, 583, 1, 887, 180, 59, 99, 12]\n",
      "[119, 800, 2, 1, 1447, 2, 63, 3, 1036, 3, 410, 102]\n",
      "[119, 800, 2, 1, 1447, 2, 63, 3, 1036, 3]\n",
      "[6, 7415, 388, 3, 1, 1001, 3741, 24, 2589, 255, 7, 57, 90, 4, 46, 15, 4378, 20, 1, 159, 4379, 21, 2854, 255]\n",
      "[6, 7415, 388, 3, 1, 1001, 3741, 24, 2589, 255]\n",
      "[11, 46, 134, 18, 1, 2167, 3, 420, 327, 74, 848, 4, 594, 376, 20, 1, 603, 1847, 1, 1848, 214]\n",
      "[11, 46, 134, 18, 1, 2167, 3, 420, 327, 74]\n"
     ]
    }
   ],
   "source": [
    "short = cut_sentences(input_integer_seq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the output: 17364\n",
      "Length of longest sentence in the output: 113\n"
     ]
    }
   ],
   "source": [
    "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "output_tokenizer.fit_on_texts(decoder_input_text + decoder_target_text)\n",
    "\n",
    "\n",
    "output_integer_seq       = output_tokenizer.texts_to_sequences(decoder_target_text)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(decoder_input_text)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "num_words_output = len(word2idx_outputs) + 2\n",
    "print('Total unique words in the output: %s' % num_words_output)\n",
    "\n",
    "\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_sen_len = [len(tok) for tok in output_integer_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  67,  70,  71,\n",
       "         75,  77,  80,  86,  89,  91],\n",
       "       [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   3,   3,   3,\n",
       "          4,   4,   5,   7,   8,  11,  22,  61,  71,  80,  93, 101, 123,\n",
       "        143, 151, 177, 187, 204, 214, 221, 249, 273, 276, 297, 300, 305,\n",
       "        347, 349, 353, 361, 365, 375, 379, 380, 380, 385, 387, 391, 396,\n",
       "        398, 412, 422, 424, 425, 441]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.unique(np.array(en_sen_len), return_counts=True),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,\n",
       "         16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "         55,  56,  57,  58,  59,  60,  61,  62,  64,  67,  68,  69,  71,\n",
       "         73,  75,  77,  79,  80,  81,  82,  83,  85,  86,  87,  95,  99,\n",
       "        103, 105, 112, 113],\n",
       "       [  1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "          1,   1,   1,   1,   2,   2,   2,   2,   2,   2,   2,   3,   3,\n",
       "          4,   4,   4,   5,   5,   8,   8,   9,  14,  15,  21,  35,  54,\n",
       "         60,  60,  85, 107, 120, 131, 137, 140, 165, 168, 176, 183, 207,\n",
       "        216, 219, 247, 250, 259, 260, 267, 267, 269, 276, 290, 290, 293,\n",
       "        297, 302, 304, 307, 320, 323, 328, 332, 335, 335, 336, 343, 345,\n",
       "        346, 347, 358, 377]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.unique(np.array(fr_sen_len), return_counts=True),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences.shape: (11000, 91)\n",
      "encoder_input_sequences[0]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0   42  155  118    1\n",
      "  338    8 7411  966 1366    7  823]\n"
     ]
    }
   ],
   "source": [
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)\n",
    "print(\"encoder_input_sequences[0]:\", encoder_input_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_input_sequences.shape: (11000, 113)\n",
      "decoder_input_sequences[0]: [   5   33  283    2 3485    9 1408 3053  358   85 4097    1    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
    "print(\"decoder_input_sequences[0]:\", decoder_input_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output_sequences.shape: (11000, 113)\n",
      "decoder_output_sequences[0]: [  33  283    2 3485    9 1408 3053  358   85 4097    1    6    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_output_sequences.shape:\", decoder_output_sequences.shape)\n",
    "print(\"decoder_output_sequences[0]:\", decoder_output_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_text(text):\n",
    "    \n",
    "    #Encoding\n",
    "    input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    input_tokenizer.fit_on_texts(text)\n",
    "    input_encoded = input_tokenizer.texts_to_sequences(text)\n",
    "    # Padding\n",
    "    input_padded = pad_sequences(input_encoded, maxlen=max_input_len)\n",
    "    \n",
    "    return input_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_output_text(text, max_len):\n",
    "    \n",
    "    #Encoding\n",
    "    input_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "    input_tokenizer.fit_on_texts(text)\n",
    "    input_encoded = input_tokenizer.texts_to_sequences(text)\n",
    "    # Padding\n",
    "    input_padded = pad_sequences(input_encoded, maxlen=max_input_len)\n",
    "    \n",
    "    return input_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2YdfpK3O_pY"
   },
   "outputs": [],
   "source": [
    "# configure problem\n",
    "embedings_dim = 64\n",
    "hidden_units = 512\n",
    "LR = 0.001\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z4-m7zcw2hqV",
    "outputId": "79978b94-9eca-418b-c4a7-1c1d20d1f710"
   },
   "outputs": [],
   "source": [
    "#en_vocab_size, en_max_len, fr_vocab_size, fr_max_len, hidden_units, embedings_dim, LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUQk9hA3bfZE"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "def seq2seq_model(num_en_tokens, embedings_dim, hidden_units, num_fr_tokens, max_input_len, max_out_len, LR, dropout):      \n",
    "    \n",
    "    encoder_inputs = layers.Input(shape=(None,))\n",
    "    encoder_embeddings = layers.Embedding(num_en_tokens, embedings_dim, mask_zero=True)\n",
    "    encoder_embedded = encoder_embeddings(encoder_inputs)\n",
    "    encoder_bilstm = layers.Bidirectional(layers.LSTM(hidden_units, return_state=True, dropout=dropout))\n",
    "    # Return states in addition to output\n",
    "    output, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_embedded)\n",
    "    \n",
    "    state_h = layers.Concatenate()([forward_h, backward_h])\n",
    "    state_c = layers.Concatenate()([forward_c, backward_c])\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    #encoder_states = [forward_h, forward_c, backward_h, backward_c]\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = layers.Input(shape=(None, ))\n",
    "    decoder_embeddings = layers.Embedding(num_fr_tokens, embedings_dim, mask_zero=True)\n",
    "    decoder_embedded = decoder_embeddings(decoder_inputs)\n",
    "\n",
    "    # Pass the 2 states to a new LSTM layer, as initial state\n",
    "    decoder_lstm = layers.LSTM(hidden_units*2, return_sequences=True, return_state=True, dropout=dropout)\n",
    "    decoder_outputs, _, _, = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
    "\n",
    "    decoder_dense = layers.Dense(num_fr_tokens, activation='linear')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.SGD(learning_rate=0.2, decay=1e-4, momentum=0.9, nesterov=True), #Adam(learning_rate=LR),\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    #sgd = SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    # Evaluation model:\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_h = layers.Input(shape=(hidden_units*2,))\n",
    "    decoder_state_c = layers.Input(shape=(hidden_units*2,))\n",
    "    #decoder_state_b_h = layers.Input(shape=(hidden_units,))\n",
    "    #decoder_state_b_c = layers.Input(shape=(hidden_units,))\n",
    "    \n",
    "    #e_state_h = layers.Concatenate()([decoder_state_f_h, decoder_state_b_h])\n",
    "    #e_state_c = layers.Concatenate()([decoder_state_f_c, decoder_state_b_c])\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_h, decoder_state_c]#, decoder_state_b_h, decoder_state_b_c]\n",
    "    \n",
    "    decoder_inputs_single = layers.Input(shape=(1,))\n",
    "    decoder_inputs_single_x = decoder_embeddings(decoder_inputs_single)\n",
    "    decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [h, c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs_single] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states\n",
    "    )\n",
    "     \n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     866432      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 1024), (None 2363392     embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     1111296     input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1024)         0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 1024), 4460544     embedding_3[0][0]                \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 17364)  17798100    lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 26,599,764\n",
      "Trainable params: 26,599,764\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model,_,_ = seq2seq_model(num_words_input, embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 91)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJVGoHjsO_pi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8800 samples, validate on 2200 samples\n",
      "Epoch 1/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.4878 - accuracy: 0.0641\n",
      "Epoch 00001: val_loss improved from inf to 1.37904, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 159s 18ms/sample - loss: 1.4879 - accuracy: 0.0642 - val_loss: 1.3790 - val_accuracy: 0.0835\n",
      "Epoch 2/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.3462 - accuracy: 0.0871\n",
      "Epoch 00002: val_loss improved from 1.37904 to 1.36537, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.3463 - accuracy: 0.0871 - val_loss: 1.3654 - val_accuracy: 0.1096\n",
      "Epoch 3/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.3218 - accuracy: 0.1134\n",
      "Epoch 00003: val_loss improved from 1.36537 to 1.34717, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.3214 - accuracy: 0.1134 - val_loss: 1.3472 - val_accuracy: 0.1167\n",
      "Epoch 4/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.3101 - accuracy: 0.1204\n",
      "Epoch 00004: val_loss improved from 1.34717 to 1.33432, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 1.3101 - accuracy: 0.1204 - val_loss: 1.3343 - val_accuracy: 0.1271\n",
      "Epoch 5/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.2891 - accuracy: 0.1296\n",
      "Epoch 00005: val_loss improved from 1.33432 to 1.31082, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 1.2892 - accuracy: 0.1296 - val_loss: 1.3108 - val_accuracy: 0.1330\n",
      "Epoch 6/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.2652 - accuracy: 0.1331\n",
      "Epoch 00006: val_loss improved from 1.31082 to 1.28899, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 1.2655 - accuracy: 0.1331 - val_loss: 1.2890 - val_accuracy: 0.1377\n",
      "Epoch 7/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.2435 - accuracy: 0.1376\n",
      "Epoch 00007: val_loss improved from 1.28899 to 1.26967, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.2432 - accuracy: 0.1376 - val_loss: 1.2697 - val_accuracy: 0.1369\n",
      "Epoch 8/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.2248 - accuracy: 0.1412\n",
      "Epoch 00008: val_loss improved from 1.26967 to 1.25449, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.2248 - accuracy: 0.1412 - val_loss: 1.2545 - val_accuracy: 0.1438\n",
      "Epoch 9/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.2091 - accuracy: 0.1461\n",
      "Epoch 00009: val_loss improved from 1.25449 to 1.24347, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.2093 - accuracy: 0.1461 - val_loss: 1.2435 - val_accuracy: 0.1459\n",
      "Epoch 10/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1953 - accuracy: 0.1502\n",
      "Epoch 00010: val_loss improved from 1.24347 to 1.23198, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.1959 - accuracy: 0.1502 - val_loss: 1.2320 - val_accuracy: 0.1516\n",
      "Epoch 11/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1836 - accuracy: 0.1553\n",
      "Epoch 00011: val_loss improved from 1.23198 to 1.22232, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.1836 - accuracy: 0.1553 - val_loss: 1.2223 - val_accuracy: 0.1579\n",
      "Epoch 12/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1718 - accuracy: 0.1607\n",
      "Epoch 00012: val_loss improved from 1.22232 to 1.21523, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.1723 - accuracy: 0.1607 - val_loss: 1.2152 - val_accuracy: 0.1599\n",
      "Epoch 13/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1623 - accuracy: 0.1641\n",
      "Epoch 00013: val_loss improved from 1.21523 to 1.20855, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.1621 - accuracy: 0.1642 - val_loss: 1.2086 - val_accuracy: 0.1617\n",
      "Epoch 14/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1537 - accuracy: 0.1656\n",
      "Epoch 00014: val_loss improved from 1.20855 to 1.20134, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.1530 - accuracy: 0.1656 - val_loss: 1.2013 - val_accuracy: 0.1677\n",
      "Epoch 15/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1439 - accuracy: 0.1689\n",
      "Epoch 00015: val_loss improved from 1.20134 to 1.19521, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.1443 - accuracy: 0.1689 - val_loss: 1.1952 - val_accuracy: 0.1675\n",
      "Epoch 16/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1360 - accuracy: 0.1705\n",
      "Epoch 00016: val_loss improved from 1.19521 to 1.19091, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.1361 - accuracy: 0.1705 - val_loss: 1.1909 - val_accuracy: 0.1693\n",
      "Epoch 17/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1285 - accuracy: 0.1723\n",
      "Epoch 00017: val_loss improved from 1.19091 to 1.18565, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.1284 - accuracy: 0.1723 - val_loss: 1.1857 - val_accuracy: 0.1722\n",
      "Epoch 18/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1207 - accuracy: 0.1748\n",
      "Epoch 00018: val_loss improved from 1.18565 to 1.18116, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.1209 - accuracy: 0.1747 - val_loss: 1.1812 - val_accuracy: 0.1736\n",
      "Epoch 19/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1137 - accuracy: 0.1762\n",
      "Epoch 00019: val_loss improved from 1.18116 to 1.17802, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 203s 23ms/sample - loss: 1.1139 - accuracy: 0.1762 - val_loss: 1.1780 - val_accuracy: 0.1750\n",
      "Epoch 20/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1066 - accuracy: 0.1786\n",
      "Epoch 00020: val_loss improved from 1.17802 to 1.17474, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 149s 17ms/sample - loss: 1.1071 - accuracy: 0.1785 - val_loss: 1.1747 - val_accuracy: 0.1778\n",
      "Epoch 21/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.1010 - accuracy: 0.1804\n",
      "Epoch 00021: val_loss improved from 1.17474 to 1.17160, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.1009 - accuracy: 0.1804 - val_loss: 1.1716 - val_accuracy: 0.1760\n",
      "Epoch 22/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0948 - accuracy: 0.1829\n",
      "Epoch 00022: val_loss improved from 1.17160 to 1.16815, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 1.0946 - accuracy: 0.1828 - val_loss: 1.1682 - val_accuracy: 0.1785\n",
      "Epoch 23/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0885 - accuracy: 0.1833\n",
      "Epoch 00023: val_loss improved from 1.16815 to 1.16616, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.0887 - accuracy: 0.1833 - val_loss: 1.1662 - val_accuracy: 0.1800\n",
      "Epoch 24/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0829 - accuracy: 0.1858\n",
      "Epoch 00024: val_loss improved from 1.16616 to 1.16250, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 149s 17ms/sample - loss: 1.0827 - accuracy: 0.1858 - val_loss: 1.1625 - val_accuracy: 0.1788\n",
      "Epoch 25/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0766 - accuracy: 0.1875\n",
      "Epoch 00025: val_loss improved from 1.16250 to 1.15980, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.0770 - accuracy: 0.1875 - val_loss: 1.1598 - val_accuracy: 0.1814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0715 - accuracy: 0.1889\n",
      "Epoch 00026: val_loss improved from 1.15980 to 1.15791, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.0716 - accuracy: 0.1888 - val_loss: 1.1579 - val_accuracy: 0.1826\n",
      "Epoch 27/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0662 - accuracy: 0.1905\n",
      "Epoch 00027: val_loss improved from 1.15791 to 1.15629, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.0661 - accuracy: 0.1905 - val_loss: 1.1563 - val_accuracy: 0.1832\n",
      "Epoch 28/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0609 - accuracy: 0.1923\n",
      "Epoch 00028: val_loss improved from 1.15629 to 1.15428, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.0610 - accuracy: 0.1923 - val_loss: 1.1543 - val_accuracy: 0.1849\n",
      "Epoch 29/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0563 - accuracy: 0.1939\n",
      "Epoch 00029: val_loss improved from 1.15428 to 1.15281, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.0559 - accuracy: 0.1940 - val_loss: 1.1528 - val_accuracy: 0.1861\n",
      "Epoch 30/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0504 - accuracy: 0.1951\n",
      "Epoch 00030: val_loss improved from 1.15281 to 1.15181, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.0508 - accuracy: 0.1951 - val_loss: 1.1518 - val_accuracy: 0.1840\n",
      "Epoch 31/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0456 - accuracy: 0.1971\n",
      "Epoch 00031: val_loss improved from 1.15181 to 1.14875, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 1.0459 - accuracy: 0.1971 - val_loss: 1.1488 - val_accuracy: 0.1873\n",
      "Epoch 32/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0412 - accuracy: 0.1987\n",
      "Epoch 00032: val_loss did not improve from 1.14875\n",
      "8800/8800 [==============================] - 148s 17ms/sample - loss: 1.0414 - accuracy: 0.1987 - val_loss: 1.1489 - val_accuracy: 0.1863\n",
      "Epoch 33/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0366 - accuracy: 0.1999\n",
      "Epoch 00033: val_loss improved from 1.14875 to 1.14772, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.0364 - accuracy: 0.1998 - val_loss: 1.1477 - val_accuracy: 0.1884\n",
      "Epoch 34/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0319 - accuracy: 0.2014\n",
      "Epoch 00034: val_loss improved from 1.14772 to 1.14547, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.0315 - accuracy: 0.2014 - val_loss: 1.1455 - val_accuracy: 0.1872\n",
      "Epoch 35/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0272 - accuracy: 0.2029\n",
      "Epoch 00035: val_loss improved from 1.14547 to 1.14394, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 1.0271 - accuracy: 0.2029 - val_loss: 1.1439 - val_accuracy: 0.1907\n",
      "Epoch 36/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0226 - accuracy: 0.2041\n",
      "Epoch 00036: val_loss improved from 1.14394 to 1.14211, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 152s 17ms/sample - loss: 1.0229 - accuracy: 0.2041 - val_loss: 1.1421 - val_accuracy: 0.1891\n",
      "Epoch 37/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0181 - accuracy: 0.2053\n",
      "Epoch 00037: val_loss did not improve from 1.14211\n",
      "8800/8800 [==============================] - 149s 17ms/sample - loss: 1.0182 - accuracy: 0.2053 - val_loss: 1.1422 - val_accuracy: 0.1898\n",
      "Epoch 38/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0136 - accuracy: 0.2073\n",
      "Epoch 00038: val_loss improved from 1.14211 to 1.14099, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 1.0138 - accuracy: 0.2073 - val_loss: 1.1410 - val_accuracy: 0.1912\n",
      "Epoch 39/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0097 - accuracy: 0.2088\n",
      "Epoch 00039: val_loss improved from 1.14099 to 1.14024, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 1.0096 - accuracy: 0.2088 - val_loss: 1.1402 - val_accuracy: 0.1914\n",
      "Epoch 40/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0051 - accuracy: 0.2097\n",
      "Epoch 00040: val_loss improved from 1.14024 to 1.13867, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.0051 - accuracy: 0.2097 - val_loss: 1.1387 - val_accuracy: 0.1934\n",
      "Epoch 41/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 1.0011 - accuracy: 0.2111\n",
      "Epoch 00041: val_loss improved from 1.13867 to 1.13840, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 1.0009 - accuracy: 0.2111 - val_loss: 1.1384 - val_accuracy: 0.1925\n",
      "Epoch 42/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9969 - accuracy: 0.2132\n",
      "Epoch 00042: val_loss improved from 1.13840 to 1.13651, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 153s 17ms/sample - loss: 0.9967 - accuracy: 0.2131 - val_loss: 1.1365 - val_accuracy: 0.1948\n",
      "Epoch 43/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9918 - accuracy: 0.2151\n",
      "Epoch 00043: val_loss improved from 1.13651 to 1.13590, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 0.9923 - accuracy: 0.2151 - val_loss: 1.1359 - val_accuracy: 0.1940\n",
      "Epoch 44/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9876 - accuracy: 0.2164\n",
      "Epoch 00044: val_loss improved from 1.13590 to 1.13585, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 0.9880 - accuracy: 0.2163 - val_loss: 1.1359 - val_accuracy: 0.1968\n",
      "Epoch 45/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9840 - accuracy: 0.2179\n",
      "Epoch 00045: val_loss improved from 1.13585 to 1.13520, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 0.9839 - accuracy: 0.2179 - val_loss: 1.1352 - val_accuracy: 0.1944\n",
      "Epoch 46/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9801 - accuracy: 0.2194\n",
      "Epoch 00046: val_loss improved from 1.13520 to 1.13419, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 0.9797 - accuracy: 0.2195 - val_loss: 1.1342 - val_accuracy: 0.1967\n",
      "Epoch 47/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9751 - accuracy: 0.2213\n",
      "Epoch 00047: val_loss improved from 1.13419 to 1.13241, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 0.9751 - accuracy: 0.2213 - val_loss: 1.1324 - val_accuracy: 0.1964\n",
      "Epoch 48/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9709 - accuracy: 0.2226\n",
      "Epoch 00048: val_loss did not improve from 1.13241\n",
      "8800/8800 [==============================] - 148s 17ms/sample - loss: 0.9709 - accuracy: 0.2226 - val_loss: 1.1325 - val_accuracy: 0.1972\n",
      "Epoch 49/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9669 - accuracy: 0.2247\n",
      "Epoch 00049: val_loss improved from 1.13241 to 1.13117, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 0.9670 - accuracy: 0.2247 - val_loss: 1.1312 - val_accuracy: 0.1998\n",
      "Epoch 50/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9630 - accuracy: 0.2270\n",
      "Epoch 00050: val_loss did not improve from 1.13117\n",
      "8800/8800 [==============================] - 148s 17ms/sample - loss: 0.9627 - accuracy: 0.2271 - val_loss: 1.1324 - val_accuracy: 0.1993\n",
      "Epoch 51/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9589 - accuracy: 0.2280\n",
      "Epoch 00051: val_loss did not improve from 1.13117\n",
      "8800/8800 [==============================] - 148s 17ms/sample - loss: 0.9589 - accuracy: 0.2279 - val_loss: 1.1316 - val_accuracy: 0.1991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9548 - accuracy: 0.2298\n",
      "Epoch 00052: val_loss improved from 1.13117 to 1.13034, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 0.9547 - accuracy: 0.2298 - val_loss: 1.1303 - val_accuracy: 0.2017\n",
      "Epoch 53/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9509 - accuracy: 0.2311\n",
      "Epoch 00053: val_loss improved from 1.13034 to 1.12948, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 0.9508 - accuracy: 0.2311 - val_loss: 1.1295 - val_accuracy: 0.2003\n",
      "Epoch 54/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9473 - accuracy: 0.2323\n",
      "Epoch 00054: val_loss improved from 1.12948 to 1.12881, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 167s 19ms/sample - loss: 0.9471 - accuracy: 0.2323 - val_loss: 1.1288 - val_accuracy: 0.1991\n",
      "Epoch 55/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9440 - accuracy: 0.2342\n",
      "Epoch 00055: val_loss did not improve from 1.12881\n",
      "8800/8800 [==============================] - 148s 17ms/sample - loss: 0.9436 - accuracy: 0.2342 - val_loss: 1.1293 - val_accuracy: 0.2002\n",
      "Epoch 56/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9400 - accuracy: 0.2348\n",
      "Epoch 00056: val_loss improved from 1.12881 to 1.12830, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 151s 17ms/sample - loss: 0.9401 - accuracy: 0.2348 - val_loss: 1.1283 - val_accuracy: 0.1998\n",
      "Epoch 57/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9365 - accuracy: 0.2362\n",
      "Epoch 00057: val_loss did not improve from 1.12830\n",
      "8800/8800 [==============================] - 227s 26ms/sample - loss: 0.9365 - accuracy: 0.2362 - val_loss: 1.1287 - val_accuracy: 0.2021\n",
      "Epoch 58/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9318 - accuracy: 0.2382\n",
      "Epoch 00058: val_loss improved from 1.12830 to 1.12788, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 150s 17ms/sample - loss: 0.9324 - accuracy: 0.2381 - val_loss: 1.1279 - val_accuracy: 0.2021\n",
      "Epoch 59/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9293 - accuracy: 0.2401\n",
      "Epoch 00059: val_loss did not improve from 1.12788\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.9291 - accuracy: 0.2401 - val_loss: 1.1285 - val_accuracy: 0.2014\n",
      "Epoch 60/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9256 - accuracy: 0.2411\n",
      "Epoch 00060: val_loss did not improve from 1.12788\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.9253 - accuracy: 0.2412 - val_loss: 1.1290 - val_accuracy: 0.2021\n",
      "Epoch 61/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9218 - accuracy: 0.2425\n",
      "Epoch 00061: val_loss improved from 1.12788 to 1.12765, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 149s 17ms/sample - loss: 0.9215 - accuracy: 0.2425 - val_loss: 1.1277 - val_accuracy: 0.2020\n",
      "Epoch 62/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9179 - accuracy: 0.2438\n",
      "Epoch 00062: val_loss did not improve from 1.12765\n",
      "8800/8800 [==============================] - 148s 17ms/sample - loss: 0.9181 - accuracy: 0.2437 - val_loss: 1.1286 - val_accuracy: 0.1996\n",
      "Epoch 63/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9145 - accuracy: 0.2455\n",
      "Epoch 00063: val_loss improved from 1.12765 to 1.12765, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 149s 17ms/sample - loss: 0.9145 - accuracy: 0.2454 - val_loss: 1.1276 - val_accuracy: 0.2012\n",
      "Epoch 64/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9113 - accuracy: 0.2459\n",
      "Epoch 00064: val_loss did not improve from 1.12765\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.9114 - accuracy: 0.2460 - val_loss: 1.1279 - val_accuracy: 0.2009\n",
      "Epoch 65/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9078 - accuracy: 0.2475\n",
      "Epoch 00065: val_loss improved from 1.12765 to 1.12701, saving model to baseline2.7.hdf5\n",
      "8800/8800 [==============================] - 148s 17ms/sample - loss: 0.9080 - accuracy: 0.2475 - val_loss: 1.1270 - val_accuracy: 0.2025\n",
      "Epoch 66/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9042 - accuracy: 0.2489\n",
      "Epoch 00066: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.9046 - accuracy: 0.2490 - val_loss: 1.1285 - val_accuracy: 0.2005\n",
      "Epoch 67/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.9011 - accuracy: 0.2514\n",
      "Epoch 00067: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.9010 - accuracy: 0.2514 - val_loss: 1.1274 - val_accuracy: 0.2015\n",
      "Epoch 68/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8973 - accuracy: 0.2531\n",
      "Epoch 00068: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8974 - accuracy: 0.2531 - val_loss: 1.1272 - val_accuracy: 0.2024\n",
      "Epoch 69/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8939 - accuracy: 0.2544\n",
      "Epoch 00069: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8943 - accuracy: 0.2544 - val_loss: 1.1272 - val_accuracy: 0.2021\n",
      "Epoch 70/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8907 - accuracy: 0.2555\n",
      "Epoch 00070: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8910 - accuracy: 0.2554 - val_loss: 1.1282 - val_accuracy: 0.2005\n",
      "Epoch 71/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8879 - accuracy: 0.2568\n",
      "Epoch 00071: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8878 - accuracy: 0.2568 - val_loss: 1.1280 - val_accuracy: 0.2009\n",
      "Epoch 72/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8848 - accuracy: 0.2574\n",
      "Epoch 00072: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8848 - accuracy: 0.2575 - val_loss: 1.1283 - val_accuracy: 0.2025\n",
      "Epoch 73/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8814 - accuracy: 0.2595\n",
      "Epoch 00073: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8814 - accuracy: 0.2595 - val_loss: 1.1300 - val_accuracy: 0.2007\n",
      "Epoch 74/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8777 - accuracy: 0.2605\n",
      "Epoch 00074: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8782 - accuracy: 0.2604 - val_loss: 1.1295 - val_accuracy: 0.2007\n",
      "Epoch 75/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8747 - accuracy: 0.2629\n",
      "Epoch 00075: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8749 - accuracy: 0.2628 - val_loss: 1.1281 - val_accuracy: 0.2035\n",
      "Epoch 76/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8717 - accuracy: 0.2641\n",
      "Epoch 00076: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8717 - accuracy: 0.2640 - val_loss: 1.1290 - val_accuracy: 0.2013\n",
      "Epoch 77/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8692 - accuracy: 0.2645\n",
      "Epoch 00077: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8691 - accuracy: 0.2644 - val_loss: 1.1297 - val_accuracy: 0.2017\n",
      "Epoch 78/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8658 - accuracy: 0.2664\n",
      "Epoch 00078: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8660 - accuracy: 0.2664 - val_loss: 1.1302 - val_accuracy: 0.1998\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8626 - accuracy: 0.2687\n",
      "Epoch 00079: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8625 - accuracy: 0.2687 - val_loss: 1.1300 - val_accuracy: 0.2029\n",
      "Epoch 80/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8598 - accuracy: 0.2691\n",
      "Epoch 00080: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8598 - accuracy: 0.2691 - val_loss: 1.1302 - val_accuracy: 0.2007\n",
      "Epoch 81/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8567 - accuracy: 0.2707\n",
      "Epoch 00081: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8568 - accuracy: 0.2708 - val_loss: 1.1308 - val_accuracy: 0.2017\n",
      "Epoch 82/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8534 - accuracy: 0.2717\n",
      "Epoch 00082: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8539 - accuracy: 0.2717 - val_loss: 1.1316 - val_accuracy: 0.1996\n",
      "Epoch 83/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8507 - accuracy: 0.2737\n",
      "Epoch 00083: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8511 - accuracy: 0.2736 - val_loss: 1.1317 - val_accuracy: 0.2010\n",
      "Epoch 84/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8482 - accuracy: 0.2748\n",
      "Epoch 00084: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8478 - accuracy: 0.2749 - val_loss: 1.1315 - val_accuracy: 0.2016\n",
      "Epoch 85/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8454 - accuracy: 0.2766\n",
      "Epoch 00085: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8453 - accuracy: 0.2766 - val_loss: 1.1323 - val_accuracy: 0.2013\n",
      "Epoch 86/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8421 - accuracy: 0.2781\n",
      "Epoch 00086: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8422 - accuracy: 0.2780 - val_loss: 1.1335 - val_accuracy: 0.2006\n",
      "Epoch 87/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8396 - accuracy: 0.2793\n",
      "Epoch 00087: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8394 - accuracy: 0.2794 - val_loss: 1.1338 - val_accuracy: 0.2014\n",
      "Epoch 88/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8369 - accuracy: 0.2799\n",
      "Epoch 00088: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8370 - accuracy: 0.2799 - val_loss: 1.1337 - val_accuracy: 0.1999\n",
      "Epoch 89/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8338 - accuracy: 0.2818\n",
      "Epoch 00089: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8340 - accuracy: 0.2819 - val_loss: 1.1347 - val_accuracy: 0.2001\n",
      "Epoch 90/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8306 - accuracy: 0.2834\n",
      "Epoch 00090: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8311 - accuracy: 0.2834 - val_loss: 1.1346 - val_accuracy: 0.1996\n",
      "Epoch 91/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8284 - accuracy: 0.2847\n",
      "Epoch 00091: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8281 - accuracy: 0.2847 - val_loss: 1.1367 - val_accuracy: 0.2018\n",
      "Epoch 92/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8259 - accuracy: 0.2866\n",
      "Epoch 00092: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8257 - accuracy: 0.2866 - val_loss: 1.1356 - val_accuracy: 0.2003\n",
      "Epoch 93/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8232 - accuracy: 0.2878\n",
      "Epoch 00093: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8229 - accuracy: 0.2879 - val_loss: 1.1364 - val_accuracy: 0.2003\n",
      "Epoch 94/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8204 - accuracy: 0.2890\n",
      "Epoch 00094: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8201 - accuracy: 0.2891 - val_loss: 1.1366 - val_accuracy: 0.1995\n",
      "Epoch 95/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8171 - accuracy: 0.2905\n",
      "Epoch 00095: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8173 - accuracy: 0.2905 - val_loss: 1.1376 - val_accuracy: 0.2015\n",
      "Epoch 96/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8149 - accuracy: 0.2913\n",
      "Epoch 00096: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8149 - accuracy: 0.2913 - val_loss: 1.1374 - val_accuracy: 0.2017\n",
      "Epoch 97/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8122 - accuracy: 0.2936\n",
      "Epoch 00097: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8123 - accuracy: 0.2935 - val_loss: 1.1387 - val_accuracy: 0.1985\n",
      "Epoch 98/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8096 - accuracy: 0.2951\n",
      "Epoch 00098: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8094 - accuracy: 0.2952 - val_loss: 1.1398 - val_accuracy: 0.1990\n",
      "Epoch 99/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8073 - accuracy: 0.2946\n",
      "Epoch 00099: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 146s 17ms/sample - loss: 0.8074 - accuracy: 0.2946 - val_loss: 1.1397 - val_accuracy: 0.2003\n",
      "Epoch 100/100\n",
      "8780/8800 [============================>.] - ETA: 0s - loss: 0.8048 - accuracy: 0.2975\n",
      "Epoch 00100: val_loss did not improve from 1.12701\n",
      "8800/8800 [==============================] - 147s 17ms/sample - loss: 0.8047 - accuracy: 0.2976 - val_loss: 1.1408 - val_accuracy: 0.1978\n"
     ]
    }
   ],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath='baseline2.7.hdf5', verbose=2, save_best_only=True)\n",
    "\n",
    "history = model.fit([encoder_input_sequences, decoder_input_sequences],\n",
    "                            decoder_output_sequences,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs, \n",
    "                            validation_split=0.2,\n",
    "                            callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "#plot_model(model, to_file = \"seq2seq_translation.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 64)     866432      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 1024), (None 2363392     embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 64)     1111296     input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1024)         0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024)         0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 1024), 4460544     embedding_5[0][0]                \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 17364)  17798100    lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 26,599,764\n",
      "Trainable params: 26,599,764\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "_, encoder_model, decoder_model = seq2seq_model(num_words_input, embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(input_seq):\n",
    "    \n",
    "    #print(input_seq.shape)\n",
    "    input_seq = input_seq.reshape(-1,max_input_len)\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs['<bos>']\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "    output_sentence = []\n",
    "    \n",
    "    #print(\"Translating sequence: \", input_seq)\n",
    "    for _ in range(max_out_len):\n",
    "        \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "            #print(\"Predicting word \"+word+\"for index \"+str(idx))\n",
    "\n",
    "        target_seq[0, 0] = idx\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        \n",
    "\n",
    "    return ' '.join(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: mr president ladies and gentlemen the financial perspective outlines the scope of the eu ’s activities over coming years as well as providing a framework for such activities and determining how effective they will be .\n",
      "==============================\n",
      "Response: blâme inquiétantes cinquantième permettent caractérisée collaboré nexi purifier pirates ironique louable support support optique deviez shah ankara placez placez mortalité épargnerait épargnerait épargnerait épargnerait épargnerait purifier naturelles réparer tremblent turc dispersées héritées optimisme habillement participent masses millions veillons radicalement radicalement sandiniste créerait résistent traducteur remise constat symphony objecteront objecteront cachet préservions place collectives n' créances fécule réel attrapées 1977 émancipatrices émancipatrices inciterais familiales capables — espèce défendre clairvoyance financés recueillir extraire janvier janvier cohérents difficulté individuelles préféré renforcées préféré renforcées baisse téléphoné républicain confirmant 1994 fléaux moqueuse affrontèrent affrontèrent admire détenu écho détenu ajustées tv6 détenu pegu contrainte office office hardy précaution hardy linked vergogne part part imposent gouvernante pratiquant gagne ivresse contraignants\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "input_seq = encoder_input_sequences[i]\n",
    "translation = translate_sentence(input_seq)\n",
    "\n",
    "print('Input:', encoder_input_text[i])\n",
    "print('==============================')\n",
    "print('Response:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['so too does the idea that accommodating religious differences is dangerous\\n', 'mr president ladies and gentlemen the financial perspective outlines the scope of the eu ’s activities over coming years as well as providing a framework for such activities and determining how effective they will be\\n', 'reserve should turn into thought - provoking policy\\n', 'it is my profound belief that we can only advance through cooperation and negotiation\\n', 'the european union has territorial waters greater than its entire territory with 1 200 ports and 90 % of its exports are transported by sea\\n']\n"
     ]
    }
   ],
   "source": [
    "text_inputs = []\n",
    "with open(os.path.join(DIRECTORY_URL, FILE_NAMES[0]), 'r', encoding='utf-8') as en_file:\n",
    "    input_text = en_file.readlines()\n",
    "    en_file.close() \n",
    "print(input_text[0:5])\n",
    "input_text = input_text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_inputs.txt\", \"w\", encoding='utf-8') as in_file:\n",
    "    in_file.writelines(input_text)\n",
    "    in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L’ idée de concilier les différences religieuses semble donc dangereuse .\\n', 'Monsieur le Président , Mesdames et Messieurs , les perspectives financières esquissent la portée des activités de l’ UE pour les années à venir , fournissent un cadre pour ces activités et déterminent leur efficacité .\\n', 'La réticence doit laisser place à une politique stimulante .\\n', 'Je suis intimement convaincu que nous ne pourrons progresser que si nous coopérons et négocions .\\n', \"Le territoire marin de l' Union européenne est plus vaste que son territoire terrestre . On y dénombre 1 200 ports et 90 % de ses exportations sont acheminées par mer .\\n\"]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "with open(os.path.join(DIRECTORY_URL, FILE_NAMES[1]), 'r', encoding='utf-8') as fr_file:\n",
    "    targets = fr_file.readlines()\n",
    "    fr_file.close() \n",
    "print(targets[0:5])\n",
    "targets = targets[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"targets.txt\", \"w\", encoding='utf-8') as target_file:\n",
    "    target_file.writelines(targets)\n",
    "    target_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def open_file(file_to_open):\n",
    "    input_text = []\n",
    "    with open(Path(file_to_open), 'r', encoding=\"UTF-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            line = line.rstrip().split('\\n')\n",
    "            input_text.append(line[0])\n",
    "        f.close()\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input_text(input_text):\n",
    "    input_text = input_tokenizer.texts_to_sequences(input_text)\n",
    "    input_text = pad_sequences(input_text, maxlen=max_input_len)\n",
    "    return input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load model parameters\n",
    "#model.load_weights(\"baseline2.h5\")\n",
    "args_input_file_path = \"text_inputs.txt\"\n",
    "#pred_file_path = \"predictions.txt\"\n",
    "\n",
    "# Load text input\n",
    "eval_input_text = open_file(args_input_file_path)\n",
    "\n",
    "# Preprocess input\n",
    "input_prep = prep_input_text(eval_input_text)\n",
    "\n",
    "# Run prediction\n",
    "translations = []\n",
    "for text in input_prep:\n",
    "    translations.append(translate_sentence(text)+\"\\n\")\n",
    "\n",
    "# Save to file\n",
    "with open(\"predictions.txt\", \"w\", encoding='utf-8') as target_file:\n",
    "    target_file.writelines(translations)\n",
    "    target_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eq0ggv-VO_py"
   },
   "source": [
    "## SacreBLEU Evaluation \n",
    "['0.3', '0.2', '0.3', '0.2', '0.3', '']\n",
    "\n",
    "final avg bleu score: 0.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project2_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('env1': venv)",
   "language": "python",
   "name": "python37664bitenv1venv65b3d667bd5b4de888060908243be41e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
