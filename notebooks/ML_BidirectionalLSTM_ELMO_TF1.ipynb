{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --no-index matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvVhUeaRO_nA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa\n",
    "#import tensorflow_datasets as tfds\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import unicodedata\n",
    "import re\n",
    "import gc\n",
    "from collections import Counter\n",
    "#import keras as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ys0Y7XsBO_nY"
   },
   "outputs": [],
   "source": [
    "#physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "#os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import numpy as np\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import h5py\n",
    "import os\n",
    "import bilm\n",
    "from bilm import Batcher, BidirectionalLanguageModel, weight_layers\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UYVG_U1HO_ne"
   },
   "source": [
    "## Preprocessing: Tokenize, clean-up, load, padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4OBlaeO_nf"
   },
   "source": [
    "### Tokenize and clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEI1uWtjO_nh"
   },
   "outputs": [],
   "source": [
    "# Lower case for the translation\n",
    "# Load original english text as is\n",
    "# install requirement.txt\n",
    "# python -m spacy download fr_core_news_sm\n",
    "# correction of tokenizer.py: add encoding='utf-8' to open method\n",
    "# same thing for punctuation_remover.py\n",
    "# python tokenizer.py --input train.lang2 --output tokenized --lang fr --keep-empty-lines\n",
    "# python punctuation_remover.py --input train.lang2.tok --output tokenized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpNtsXsjO_nn"
   },
   "source": [
    "### Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5nxMfzAO_no"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "textdir = \"data/train/\"\n",
    "fr_text_file = os.path.join(textdir, 'train.lang2')\n",
    "en_text_file = os.path.join(textdir, 'train.lang1')\n",
    "\n",
    "#FILE_NAMES = [\"train.lang1\",\"train.lang2\"]\n",
    "#ELMo_Embeddings = [\"new_ELMo_input_en_embeddings.hdf5\",\"ELMo_emb_fr.hdf5\"]\n",
    "\n",
    "datadir = \"ELMo/\"\n",
    "Elmo_emb_dec_input_file = os.path.join(datadir, 'swb_fr/', 'ELMo_decoder_input_embeddings.hdf5')\n",
    "Elmo_emb_dec_targets_file = os.path.join(datadir, 'swb_fr/', 'ELMo_decoder_output_embeddings.hdf5')\n",
    "\n",
    "fr_vocab_file = os.path.join(datadir, 'swb_fr/', 'vocab.txt')\n",
    "fr_options_file = os.path.join(datadir, 'swb_fr/', 'options_eval_fr.json')\n",
    "fr_weight_file = os.path.join(datadir, 'swb_fr/', 'swb_weights_fr.hdf5')\n",
    "\n",
    "Elmo_emb_enc_file = os.path.join(datadir, 'swb_en/', 'ELMo_encoder_embeddings_post.hdf5')\n",
    "en_vocab_file = os.path.join(datadir, 'swb_en/', 'vocab.txt')\n",
    "en_options_file = os.path.join(datadir, 'swb_en/', 'options_eval.json')\n",
    "en_weight_file = os.path.join(datadir, 'swb_en/', 'swb_weights_en.hdf5')\n",
    "\n",
    "\n",
    "SOS_ELMo_emb_file = os.path.join(datadir, '../', 'SOS_ELMo_emb.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_elmo_emb = h5py.File(Elmo_emb_enc_file, 'r')\n",
    "fr_elmo_emb = h5py.File(Elmo_emb_dec_input_file, 'r')\n",
    "#fr_elmo_emb_targets = h5py.File(Elmo_emb_dec_targets_file, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>', '<S>', '</S>', '<UNK>', 'the', 'to', 'of', 'and', 'in', 'a']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab = []\n",
    "with open(en_vocab_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        en_vocab.append(line[0])\n",
    "    f.close()\n",
    "\n",
    "en_vocab = ['<PAD>'] + en_vocab\n",
    "en_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input lang tokens:  165670\n"
     ]
    }
   ],
   "source": [
    "en_word2idx = {v:k for k, v in enumerate(en_vocab)}\n",
    "#print(en_word2idx)\n",
    "num_words_input = len(en_word2idx)\n",
    "print(\"Number of input lang tokens: \",num_words_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>', '<S>', '</S>', '<UNK>', 'de', '.', ',', 'la', 'et', 'le']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocab = []\n",
    "with open(fr_vocab_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        fr_vocab.append(line[0])\n",
    "    f.close()\n",
    "\n",
    "fr_vocab = ['<PAD>'] + fr_vocab\n",
    "fr_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of output lang tokens:  83332\n"
     ]
    }
   ],
   "source": [
    "fr_word2idx = {v:k for k, v in enumerate(fr_vocab)}\n",
    "fr_idx2word = {k:v for k, v in enumerate(fr_vocab)}\n",
    "#print(fr_word2idx)\n",
    "num_words_output = len(fr_word2idx)\n",
    "print(\"Number of output lang tokens: \",num_words_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ELMo embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder embeddings\n",
    "dset = list(en_elmo_emb.keys())[0]\n",
    "encoder_input_sequences = en_elmo_emb[dset][()]\n",
    "en_elmo_emb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 96, 256)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max input sentence length\n",
    "max_input_len = encoder_input_sequences.shape[1]\n",
    "max_input_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9377234 ,  0.11211856, -1.815702  , ..., -1.0165986 ,\n",
       "         0.2566865 , -1.4266841 ],\n",
       "       [ 0.76397216, -0.72957176, -1.2059255 , ..., -0.53055835,\n",
       "        -0.28045744, -1.6430402 ],\n",
       "       [-0.09817386, -2.4250271 ,  1.2986397 , ...,  0.80349994,\n",
       "         0.70233214, -3.0202804 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder input embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder input embeddings\n",
    "dset = list(fr_elmo_emb.keys())[0]\n",
    "decoder_input_sequences = fr_elmo_emb[dset][()]\n",
    "fr_elmo_emb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113, 256)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max input sentence length\n",
    "max_out_len = decoder_input_sequences.shape[1]\n",
    "max_out_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3515264 , -0.4155752 , -1.1044897 , ..., -0.6278715 ,\n",
       "         1.9337945 , -1.7928498 ],\n",
       "       [ 1.0957094 ,  0.7679421 ,  1.6110834 , ...,  0.3838907 ,\n",
       "        -0.34145802,  1.4356495 ],\n",
       "       [ 0.7996905 ,  0.6359963 ,  0.70580614, ..., -0.95944005,\n",
       "         1.1262033 , -1.3790954 ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_sequences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load french train text\n",
    "decoder_target_text = []\n",
    "\n",
    "with open(fr_text_file, 'r', encoding=\"UTF-8\") as fr_file:\n",
    "    for line in fr_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "\n",
    "        target_line = line[0]+\" </S>\"\n",
    "        #input_line = \"<S> \"+line[0]+\"\\n\"\n",
    "\n",
    "        #decoder_input_text.append(input_line)\n",
    "        decoder_target_text.append(target_line)\n",
    "    fr_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L’ idée de concilier les différences religieuses semble donc dangereuse . </S>',\n",
       " 'Monsieur le Président , Mesdames et Messieurs , les perspectives financières esquissent la portée des activités de l’ UE pour les années à venir , fournissent un cadre pour ces activités et déterminent leur efficacité . </S>',\n",
       " 'La réticence doit laisser place à une politique stimulante . </S>']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "tokenized_context = [sentence.split() for sentence in decoder_target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_context[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_word(word, encode_dict):\n",
    "    #print(encode_dict.get(word))\n",
    "    if encode_dict.get(word)==None:\n",
    "        if encode_dict.get(word.lower())==None:\n",
    "            return encode_dict.get('<UNK>')\n",
    "        else:\n",
    "            return encode_dict.get(word.lower())\n",
    "    else:\n",
    "        return encode_dict.get(word)\n",
    "    \n",
    "def encode_sequence(seq, encode_dict):\n",
    "    #print([j.lower() for j in seq])\n",
    "    return [get_idx_from_word(j, encode_dict) for j in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_from_idx(idx, decode_dict):\n",
    "    if decode_dict.get(idx)==None:\n",
    "        return '<UNK>'\n",
    "    else:\n",
    "        return decode_dict.get(idx)\n",
    "\n",
    "def decode_sequence(seq, decode_dict):\n",
    "    return [get_word_from_idx(j, decode_dict) for j in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx = encode_sequence(tokenized_context[1],fr_word2idx)\n",
    "#idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<PAD>']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = decode_sequence([0],fr_idx2word)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build decoder targets\n",
    "for i, seq in enumerate(tokenized_context):\n",
    "    new_seq = pad_sequences([encode_sequence(seq, fr_word2idx)], padding='post', maxlen=max_out_len)\n",
    "    if i==0:\n",
    "        decoder_output_sequences = new_seq\n",
    "    else:\n",
    "        decoder_output_sequences = np.vstack((decoder_output_sequences, new_seq))\n",
    "        \n",
    "#decoder_output_sequences = numpy.array([numpy.array(xi) for xi in x])\n",
    "\n",
    "decoder_output_sequences.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   73,     9,    69,     6,   444,     8,   421,     6,    10,\n",
       "        1116,   769,     3,     7,  1786,    13,   685,     4,    34,\n",
       "         132,    22,    10,   179,    11,   662,     6,  4906,    19,\n",
       "         195,    22,    50,   685,     8, 10181,    83,   705,     5,\n",
       "           2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode_sequence(decoder_output_sequences[1],fr_idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2YdfpK3O_pY"
   },
   "outputs": [],
   "source": [
    "# configure problem\n",
    "embedings_dim = encoder_input_sequences.shape[2]\n",
    "hidden_units = 512\n",
    "LR = 0.001\n",
    "dropout = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z4-m7zcw2hqV",
    "outputId": "79978b94-9eca-418b-c4a7-1c1d20d1f710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 512, 83332, 96, 113, 0.001, 0.4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nUQk9hA3bfZE"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "def seq2seq_model(embedings_dim, hidden_units, num_fr_tokens, max_input_len, max_out_len, LR, dropout):      \n",
    "    \n",
    "    encoder_inputs = layers.Input(shape=(max_input_len, embedings_dim,), name='encoder_input')\n",
    "    #encoder_embeddings = layers.Embedding(num_en_tokens, embedings_dim, mask_zero=True)\n",
    "    #encoder_embedded = encoder_embeddings(encoder_inputs)\n",
    "    encoder_bilstm = layers.Bidirectional(layers.LSTM(hidden_units, return_state=True, dropout=dropout), name='encoder_BiLSTM')\n",
    "    # Return states in addition to output\n",
    "    output, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs) # replace embeddings by the encoder input\n",
    "    \n",
    "    state_h = concatenate([forward_h, backward_h])\n",
    "    state_c = concatenate([forward_c, backward_c])\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    #encoder_states = [forward_h, forward_c, backward_h, backward_c]\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = layers.Input(shape=(max_out_len, embedings_dim,), name='decoder_input')\n",
    "    #decoder_embeddings = layers.Embedding(num_fr_tokens, embedings_dim, mask_zero=True)\n",
    "    #decoder_embedded = decoder_embeddings(decoder_inputs)\n",
    "\n",
    "    # Pass the 2 states to a new LSTM layer, as initial state\n",
    "    decoder_lstm = layers.LSTM(hidden_units*2, return_sequences=True, return_state=True, dropout=dropout, name='decoder_LSTM')\n",
    "    decoder_outputs, _, _, = decoder_lstm(decoder_inputs, initial_state=encoder_states) #replace embeddings by decoder inputs\n",
    "\n",
    "    decoder_dense = layers.Dense(num_fr_tokens, activation='linear', name='decoder_output')                     \n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    # Set Optimizer\n",
    "    #opt = tf.keras.optimizers.SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True) #Adam(learning_rate=LR)\n",
    "    # k.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none'),\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-3), #momentum=0.9, nesterov=True),\n",
    "                  metrics=['sparse_categorical_accuracy'],             \n",
    "                 )\n",
    "    model.summary()\n",
    "    \n",
    "    # Evaluation model:\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_h = layers.Input(shape=(hidden_units*2,))\n",
    "    decoder_state_c = layers.Input(shape=(hidden_units*2,))\n",
    "    #decoder_state_b_h = layers.Input(shape=(hidden_units,))\n",
    "    #decoder_state_b_c = layers.Input(shape=(hidden_units,))\n",
    "    \n",
    "    #e_state_h = layers.Concatenate()([decoder_state_f_h, decoder_state_b_h])\n",
    "    #e_state_c = layers.Concatenate()([decoder_state_f_c, decoder_state_b_c])\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_h, decoder_state_c]#, decoder_state_b_h, decoder_state_b_c]\n",
    "    \n",
    "    decoder_inputs_single = layers.Input(shape=(max_out_len, embedings_dim,)) #layers.Input(shape=(1,))\n",
    "    #decoder_inputs_single_x = decoder_embeddings(decoder_inputs_single)\n",
    "    decoder_outputs, h, c = decoder_lstm(decoder_inputs_single, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [h, c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs_single] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states\n",
    "    )\n",
    "     \n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0418 03:49:47.576259 47785625650176 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0418 03:49:47.577774 47785625650176 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0418 03:49:47.580521 47785625650176 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0418 03:49:47.603542 47785625650176 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = seq2seq_model(embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout)\n",
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ELMO_weights_TF120200418-034949_.hdf5', 'ELMO_history_TF120200418-034949')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_file = \"ELMO_weights_TF1\"+ dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\"_.hdf5\"\n",
    "history_file = \"ELMO_history_TF1\"+ dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "weights_file, history_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11000, 113), (11000, 96, 256), (11000, 113, 256))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences.shape, encoder_input_sequences.shape, decoder_input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 113, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_sequences = np.expand_dims(decoder_output_sequences, -1)\n",
    "decoder_output_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_input_sequences)*.8/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJVGoHjsO_pi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 03:49:52.410098 47785625650176 deprecation.py:323] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8800 samples, validate on 2200 samples\n",
      "Epoch 1/50\n",
      "8800/8800 [==============================] - 772s 88ms/sample - loss: 1.4058 - sparse_categorical_accuracy: 0.8228 - val_loss: 1.0248 - val_sparse_categorical_accuracy: 0.8416\n",
      "Epoch 2/50\n",
      "8800/8800 [==============================] - 771s 88ms/sample - loss: 0.9011 - sparse_categorical_accuracy: 0.8506 - val_loss: 0.8703 - val_sparse_categorical_accuracy: 0.8563\n",
      "Epoch 3/50\n",
      "8800/8800 [==============================] - 765s 87ms/sample - loss: 0.7546 - sparse_categorical_accuracy: 0.8623 - val_loss: 0.7938 - val_sparse_categorical_accuracy: 0.8664\n",
      "Epoch 4/50\n",
      "8800/8800 [==============================] - 771s 88ms/sample - loss: 0.6572 - sparse_categorical_accuracy: 0.8709 - val_loss: 0.7507 - val_sparse_categorical_accuracy: 0.8723\n",
      "Epoch 5/50\n",
      "8800/8800 [==============================] - 770s 87ms/sample - loss: 0.5857 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.7227 - val_sparse_categorical_accuracy: 0.8772\n",
      "Epoch 6/50\n",
      "8800/8800 [==============================] - 772s 88ms/sample - loss: 0.5308 - sparse_categorical_accuracy: 0.8848 - val_loss: 0.7044 - val_sparse_categorical_accuracy: 0.8806\n",
      "Epoch 7/50\n",
      "8800/8800 [==============================] - 772s 88ms/sample - loss: 0.4874 - sparse_categorical_accuracy: 0.8916 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.8825\n",
      "Epoch 8/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.4528 - sparse_categorical_accuracy: 0.8977 - val_loss: 0.6831 - val_sparse_categorical_accuracy: 0.8844\n",
      "Epoch 9/50\n",
      "8800/8800 [==============================] - 772s 88ms/sample - loss: 0.4242 - sparse_categorical_accuracy: 0.9034 - val_loss: 0.6752 - val_sparse_categorical_accuracy: 0.8863\n",
      "Epoch 10/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.4008 - sparse_categorical_accuracy: 0.9081 - val_loss: 0.6699 - val_sparse_categorical_accuracy: 0.8875\n",
      "Epoch 11/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.3817 - sparse_categorical_accuracy: 0.9118 - val_loss: 0.6642 - val_sparse_categorical_accuracy: 0.8885\n",
      "Epoch 12/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.3636 - sparse_categorical_accuracy: 0.9158 - val_loss: 0.6618 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 13/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.3499 - sparse_categorical_accuracy: 0.9185 - val_loss: 0.6590 - val_sparse_categorical_accuracy: 0.8897\n",
      "Epoch 14/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.3375 - sparse_categorical_accuracy: 0.9212 - val_loss: 0.6549 - val_sparse_categorical_accuracy: 0.8912\n",
      "Epoch 15/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.3255 - sparse_categorical_accuracy: 0.9237 - val_loss: 0.6529 - val_sparse_categorical_accuracy: 0.8914\n",
      "Epoch 16/50\n",
      "8800/8800 [==============================] - 774s 88ms/sample - loss: 0.3157 - sparse_categorical_accuracy: 0.9258 - val_loss: 0.6518 - val_sparse_categorical_accuracy: 0.8922\n",
      "Epoch 17/50\n",
      "8800/8800 [==============================] - 774s 88ms/sample - loss: 0.3070 - sparse_categorical_accuracy: 0.9277 - val_loss: 0.6489 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 18/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.2988 - sparse_categorical_accuracy: 0.9293 - val_loss: 0.6482 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 19/50\n",
      "8800/8800 [==============================] - 774s 88ms/sample - loss: 0.2911 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.6468 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 20/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.2845 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.6458 - val_sparse_categorical_accuracy: 0.8934\n",
      "Epoch 21/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.2780 - sparse_categorical_accuracy: 0.9338 - val_loss: 0.6451 - val_sparse_categorical_accuracy: 0.8940\n",
      "Epoch 22/50\n",
      "8800/8800 [==============================] - 774s 88ms/sample - loss: 0.2731 - sparse_categorical_accuracy: 0.9347 - val_loss: 0.6437 - val_sparse_categorical_accuracy: 0.8944\n",
      "Epoch 23/50\n",
      "8800/8800 [==============================] - 772s 88ms/sample - loss: 0.2667 - sparse_categorical_accuracy: 0.9362 - val_loss: 0.6426 - val_sparse_categorical_accuracy: 0.8949\n",
      "Epoch 24/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.2610 - sparse_categorical_accuracy: 0.9373 - val_loss: 0.6422 - val_sparse_categorical_accuracy: 0.8952\n",
      "Epoch 25/50\n",
      "8800/8800 [==============================] - 773s 88ms/sample - loss: 0.2568 - sparse_categorical_accuracy: 0.9383 - val_loss: 0.6423 - val_sparse_categorical_accuracy: 0.8954\n",
      "Epoch 26/50\n",
      "8800/8800 [==============================] - 774s 88ms/sample - loss: 0.2522 - sparse_categorical_accuracy: 0.9393 - val_loss: 0.6416 - val_sparse_categorical_accuracy: 0.8952\n",
      "Epoch 27/50\n",
      "8800/8800 [==============================] - 777s 88ms/sample - loss: 0.2484 - sparse_categorical_accuracy: 0.9402 - val_loss: 0.6415 - val_sparse_categorical_accuracy: 0.8955\n",
      "Epoch 28/50\n",
      "8800/8800 [==============================] - 779s 88ms/sample - loss: 0.2439 - sparse_categorical_accuracy: 0.9412 - val_loss: 0.6425 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 29/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2400 - sparse_categorical_accuracy: 0.9419 - val_loss: 0.6413 - val_sparse_categorical_accuracy: 0.8958\n",
      "Epoch 30/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2365 - sparse_categorical_accuracy: 0.9426 - val_loss: 0.6406 - val_sparse_categorical_accuracy: 0.8961\n",
      "Epoch 31/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2329 - sparse_categorical_accuracy: 0.9433 - val_loss: 0.6405 - val_sparse_categorical_accuracy: 0.8962\n",
      "Epoch 32/50\n",
      "8800/8800 [==============================] - 779s 88ms/sample - loss: 0.2302 - sparse_categorical_accuracy: 0.9439 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 33/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2267 - sparse_categorical_accuracy: 0.9449 - val_loss: 0.6405 - val_sparse_categorical_accuracy: 0.8965\n",
      "Epoch 34/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2239 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.6399 - val_sparse_categorical_accuracy: 0.8966\n",
      "Epoch 35/50\n",
      "8800/8800 [==============================] - 779s 88ms/sample - loss: 0.2211 - sparse_categorical_accuracy: 0.9461 - val_loss: 0.6400 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 36/50\n",
      "8800/8800 [==============================] - 779s 88ms/sample - loss: 0.2177 - sparse_categorical_accuracy: 0.9468 - val_loss: 0.6406 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 37/50\n",
      "8800/8800 [==============================] - 778s 88ms/sample - loss: 0.2152 - sparse_categorical_accuracy: 0.9472 - val_loss: 0.6401 - val_sparse_categorical_accuracy: 0.8973\n",
      "Epoch 38/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2130 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.8972\n",
      "Epoch 39/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2106 - sparse_categorical_accuracy: 0.9484 - val_loss: 0.6407 - val_sparse_categorical_accuracy: 0.8969\n",
      "Epoch 40/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2081 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.6411 - val_sparse_categorical_accuracy: 0.8971\n",
      "Epoch 41/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2056 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.6412 - val_sparse_categorical_accuracy: 0.8973\n",
      "Epoch 42/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2034 - sparse_categorical_accuracy: 0.9501 - val_loss: 0.6414 - val_sparse_categorical_accuracy: 0.8972\n",
      "Epoch 43/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.2010 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 44/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.1997 - sparse_categorical_accuracy: 0.9507 - val_loss: 0.6418 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 45/50\n",
      "8800/8800 [==============================] - 779s 89ms/sample - loss: 0.1970 - sparse_categorical_accuracy: 0.9516 - val_loss: 0.6414 - val_sparse_categorical_accuracy: 0.8977\n",
      "Epoch 46/50\n",
      "8800/8800 [==============================] - 778s 88ms/sample - loss: 0.1952 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.6423 - val_sparse_categorical_accuracy: 0.8976\n",
      "Epoch 47/50\n",
      "8800/8800 [==============================] - 774s 88ms/sample - loss: 0.1935 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.6424 - val_sparse_categorical_accuracy: 0.8978\n",
      "Epoch 48/50\n",
      "8800/8800 [==============================] - 770s 88ms/sample - loss: 0.1911 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.6429 - val_sparse_categorical_accuracy: 0.8977\n",
      "Epoch 49/50\n",
      "8800/8800 [==============================] - 770s 88ms/sample - loss: 0.1901 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.6427 - val_sparse_categorical_accuracy: 0.8976\n",
      "Epoch 50/50\n",
      "8800/8800 [==============================] - 770s 88ms/sample - loss: 0.1883 - sparse_categorical_accuracy: 0.9536 - val_loss: 0.6422 - val_sparse_categorical_accuracy: 0.8979\n"
     ]
    }
   ],
   "source": [
    "#checkpointer = tf.compat.v2.keras.callbacks.ModelCheckpoint(filepath = weights_file, verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit([encoder_input_sequences, decoder_input_sequences],\n",
    "                    decoder_output_sequences,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs, \n",
    "                    #validation_steps=batch_size,\n",
    "                    validation_split=0.2,\n",
    "                    #callbacks=[checkpointer]\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(history_file, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = pickle.load(open(history_file, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history2['sparse_categorical_accuracy'])\n",
    "plt.plot(history2['val_sparse_categorical_accuracy'])\n",
    "plt.title('model/ accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history2['loss'])\n",
    "plt.plot(history2['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the weights\n",
    "#model.load_weights('ELMO_weights_20200416-042652_.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "#plot_model(model, to_file = \"seq2seq_translation.png\", show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_emb2(idx):\n",
    "    return encoder_input_sequences[idx].reshape(-1,96,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.9377234 ,  0.11211856, -1.815702  , ..., -1.0165986 ,\n",
       "          0.2566865 , -1.4266841 ],\n",
       "        [ 0.76397216, -0.72957176, -1.2059255 , ..., -0.53055835,\n",
       "         -0.28045744, -1.6430402 ],\n",
       "        [-0.09817386, -2.4250271 ,  1.2986397 , ...,  0.80349994,\n",
       "          0.70233214, -3.0202804 ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_elmo_emb2(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo_emb(input_seq, max_length, options_file, weight_file, vocab_file):\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Create a Batcher to map text to character ids.\n",
    "    batcher = Batcher(vocab_file, 50)\n",
    " \n",
    "    # Input placeholders to the biLM.\n",
    "    context_character_ids = tf.compat.v1.placeholder('int32', shape=(None, None, 50))\n",
    " \n",
    "    # Build the biLM graph.\n",
    "    bilm = BidirectionalLanguageModel(options_file, weight_file)\n",
    " \n",
    "    # Get ops to compute the LM embeddings.\n",
    "    context_embeddings_op = bilm(context_character_ids)\n",
    "     \n",
    "    # Get an op to compute ELMo (weighted average of the internal biLM layers)\n",
    "    elmo_context_input = weight_layers('input', context_embeddings_op, l2_coef=0.0)\n",
    "    \n",
    "    # Now we can compute embeddings.\n",
    "    #print(\"get elmo: input_seq=\",input_seq)\n",
    "    tokenized_context = [input_seq.split()] # for sentence in input_seq]\n",
    "    #print(tokenized_context)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # It is necessary to initialize variables once before running inference.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    " \n",
    "        # Create batches of data.\n",
    "        context_ids = batcher.batch_sentences(tokenized_context)\n",
    "        #print(\"Shape of context ids = \", context_ids.shape)\n",
    " \n",
    "        # Compute ELMo representations (here for the input only, for simplicity).\n",
    "        elmo_context_input_ = sess.run(\n",
    "            elmo_context_input['weighted_op'],\n",
    "            feed_dict={context_character_ids: context_ids}\n",
    "        )\n",
    "    # Pad the output to max sequence length of the model\n",
    "    elmo_emb = pad_sequences(elmo_context_input_, maxlen=max_length, padding='post', dtype='float32')\n",
    "    #print(\"Shape of generated embeddings = \",elmo_emb.shape)\n",
    "    return elmo_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(idx, sentence):\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    #tf.reset_default_graph()\n",
    "    global graph\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    \n",
    "    # Get ELMo embeddings\n",
    "    print(\"Get ELMo context for the input sentence: \", sentence)\n",
    "    input_seq = get_elmo_emb(sentence, max_input_len, en_options_file, en_weight_file, en_vocab_file)  # get ELMO embeddings calculated beforehand on input text\n",
    "    #print(input_seq)\n",
    "    \n",
    "    # Get encoder states value\n",
    "    print(\"Feed input context encoder model ...\")\n",
    "    with graph.as_default():\n",
    "        states_value = encoder_model.predict(input_seq)\n",
    "    #print(\"states_value=\",states_value[0].shape)\n",
    "    \n",
    "    # Feed the decoder a token at the time, starting with <S> token\n",
    "    print(\"Feed the decoder with start token ...\")\n",
    "    target_seq = get_elmo_emb('<S>', max_out_len, fr_options_file, fr_weight_file, fr_vocab_file) #['<S>']\n",
    "    \n",
    "    eos1 = fr_word2idx['</S>']\n",
    "    eos2 = fr_word2idx['.']\n",
    "    eos3 = fr_word2idx['<PAD>']\n",
    "    output_sentence = []\n",
    "    \n",
    "    print(\"Translating the input ...\")\n",
    "    for _ in range(max_out_len):\n",
    "        #print(\"Next target_seq=\",target_seq.shape)\n",
    "        with graph.as_default():\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "        #print(\"new idx=\",idx)\n",
    "        \n",
    "        if ((eos1 == idx) or (eos2 == idx) or (idx==0)):\n",
    "            break\n",
    "        else:\n",
    "            word = decode_sequence([idx],fr_idx2word) #fr_idx2word(idx)\n",
    "            output_sentence.append(word[0]+\" \")\n",
    "            #print(\"Predicting word \"+str(word)+\"for index \"+str(idx))\n",
    "\n",
    "        target_seq = get_elmo_emb(word[0],max_out_len, fr_options_file, fr_weight_file, fr_vocab_file)\n",
    "        states_value = [h, c]\n",
    "        \n",
    "        \n",
    "\n",
    "    return ' '.join(str(v) for v in output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load test data\n",
    "input_text = []\n",
    "with open(en_text_file, 'r', encoding=\"UTF-8\") as en_file:\n",
    "    for line in en_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        input_text.append(line[0])\n",
    "    en_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_text = []\n",
    "with open(fr_text_file, 'r', encoding=\"UTF-8\") as fr_file:\n",
    "    for line in fr_file.readlines():\n",
    "        line = line.rstrip().split('\\n')\n",
    "        target_text.append(line[0])\n",
    "    fr_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.random.randint(0,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i am aware of the problems the trouble and the annoyance caused to communities living next to major road transport arteries and this is why we are looking at how we can improve the quality of this traffic',\n",
       " \"Je connais les problèmes , les inconvénients et les gênes dont souffrent les populations riveraines des grands axes de trafic routier et , à cet égard , nous étudions la façon d' améliorer la qualité de ce trafic .\")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[ids[0]], target_text[ids[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  i am aware of the problems the trouble and the annoyance caused to communities living next to major road transport arteries and this is why we are looking at how we can improve the quality of this traffic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 14:35:53.862457 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/model.py:276: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0418 14:35:53.863878 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/model.py:333: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0418 14:35:53.989645 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/model.py:378: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0418 14:35:53.996208 47785625650176 deprecation.py:506] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py:180: calling squeeze (from tensorflow.python.ops.array_ops) with squeeze_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "W0418 14:35:54.546835 47785625650176 deprecation.py:323] From /home/guest142/Project2/Notebooks/bilm/model.py:524: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0418 14:35:54.572346 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/model.py:568: The name tf.nn.rnn_cell.LSTMStateTuple is deprecated. Please use tf.compat.v1.nn.rnn_cell.LSTMStateTuple instead.\n",
      "\n",
      "W0418 14:35:54.573017 47785625650176 deprecation.py:323] From /home/guest142/Project2/Notebooks/bilm/model.py:569: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "W0418 14:35:54.676841 47785625650176 deprecation.py:323] From /home/guest142/env2/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING SKIP CONNECTIONS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0418 14:35:54.858140 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/model.py:593: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "W0418 14:35:54.875532 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/model.py:538: The name tf.nn.rnn_cell.ResidualWrapper is deprecated. Please use tf.compat.v1.nn.rnn_cell.ResidualWrapper instead.\n",
      "\n",
      "W0418 14:35:55.974122 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/elmo.py:94: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0418 14:35:55.975075 47785625650176 module_wrapper.py:139] From /home/guest142/Project2/Notebooks/bilm/elmo.py:95: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  and so the spongy soil not only resists erosion but sets up a microbial universe that gives rise to a plurality of other organisms\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  a concerted approach to the challenges posed by mental health is very important and should be tackled with the same seriousness as physical health\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  yet his agenda is stalled and the country ’s ideological divisions grow deeper\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  aceh province in indonesia was previously largely closed to outsiders it was ruled by the indonesian army which fought a brutal civil war against the separatist free aceh movement\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  at the same time i support an agricultural policy which is orientated as much as possible to ensuring access for eu agricultural products to third country markets\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  the change to organic farming must be a free decision on the part of farmers and to be successful it must take place gradually\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  the uk proposal does not even take account of the geographical diversity of the member states and cuts those structural funds that are vital to southern and eastern europe\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "Response:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 96, 256)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_BiLSTM (Bidirectional)  [(None, 1024), (None 3149824     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, 113, 256)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1024)         0           encoder_BiLSTM[0][1]             \n",
      "                                                                 encoder_BiLSTM[0][3]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder_BiLSTM[0][2]             \n",
      "                                                                 encoder_BiLSTM[0][4]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_LSTM (LSTM)             [(None, 113, 1024),  5246976     decoder_input[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, 113, 83332)   85415300    decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 93,812,100\n",
      "Trainable params: 93,812,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "==============================\n",
      "Get ELMo context for the input sentence:  he is the most valuable player in our team\n",
      "USING SKIP CONNECTIONS\n",
      "Feed input context encoder model ...\n",
      "Feed the decoder with start token ...\n",
      "USING SKIP CONNECTIONS\n",
      "Translating the input ...\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n",
      "USING SKIP CONNECTIONS\n"
     ]
    }
   ],
   "source": [
    "# Run prediction on 10 samples\n",
    "predictions = []\n",
    "for i in ids:\n",
    "    _, encoder_model, decoder_model = seq2seq_model(embedings_dim, hidden_units, num_words_output, max_input_len, max_out_len, LR, dropout)\n",
    "    graph = tf.get_default_graph()\n",
    "    print('==============================')\n",
    "    #print('Input:', input_text[i])\n",
    "    translation = translate_sentence(i, input_text[i])\n",
    "    print('Response:', )\n",
    "    predictions.append(translation[0]+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"targets.txt\", \"w\", encoding='utf-8') as target_file:\n",
    "    target_file.writelines(targets)\n",
    "    target_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predictions.txt\", \"w\", encoding='utf-8') as target_file:\n",
    "    target_file.writelines(predictions)\n",
    "    target_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eq0ggv-VO_py"
   },
   "source": [
    "## SacreBLEU Evaluation "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!python evaluator.py --input-file-path predictions.txt --target-file-path targets.txt --do-not-run-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project2_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
